{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "32fc9325",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ab99d7a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.5.3'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ead30b05",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ArrowDtype',\n",
       " 'BooleanDtype',\n",
       " 'Categorical',\n",
       " 'CategoricalDtype',\n",
       " 'CategoricalIndex',\n",
       " 'DataFrame',\n",
       " 'DateOffset',\n",
       " 'DatetimeIndex',\n",
       " 'DatetimeTZDtype',\n",
       " 'ExcelFile',\n",
       " 'ExcelWriter',\n",
       " 'Flags',\n",
       " 'Float32Dtype',\n",
       " 'Float64Dtype',\n",
       " 'Float64Index',\n",
       " 'Grouper',\n",
       " 'HDFStore',\n",
       " 'Index',\n",
       " 'IndexSlice',\n",
       " 'Int16Dtype',\n",
       " 'Int32Dtype',\n",
       " 'Int64Dtype',\n",
       " 'Int64Index',\n",
       " 'Int8Dtype',\n",
       " 'Interval',\n",
       " 'IntervalDtype',\n",
       " 'IntervalIndex',\n",
       " 'MultiIndex',\n",
       " 'NA',\n",
       " 'NaT',\n",
       " 'NamedAgg',\n",
       " 'Period',\n",
       " 'PeriodDtype',\n",
       " 'PeriodIndex',\n",
       " 'RangeIndex',\n",
       " 'Series',\n",
       " 'SparseDtype',\n",
       " 'StringDtype',\n",
       " 'Timedelta',\n",
       " 'TimedeltaIndex',\n",
       " 'Timestamp',\n",
       " 'UInt16Dtype',\n",
       " 'UInt32Dtype',\n",
       " 'UInt64Dtype',\n",
       " 'UInt64Index',\n",
       " 'UInt8Dtype',\n",
       " '__all__',\n",
       " '__builtins__',\n",
       " '__cached__',\n",
       " '__deprecated_num_index_names',\n",
       " '__dir__',\n",
       " '__doc__',\n",
       " '__docformat__',\n",
       " '__file__',\n",
       " '__getattr__',\n",
       " '__git_version__',\n",
       " '__loader__',\n",
       " '__name__',\n",
       " '__package__',\n",
       " '__path__',\n",
       " '__spec__',\n",
       " '__version__',\n",
       " '_config',\n",
       " '_is_numpy_dev',\n",
       " '_libs',\n",
       " '_testing',\n",
       " '_typing',\n",
       " '_version',\n",
       " 'annotations',\n",
       " 'api',\n",
       " 'array',\n",
       " 'arrays',\n",
       " 'bdate_range',\n",
       " 'compat',\n",
       " 'concat',\n",
       " 'core',\n",
       " 'crosstab',\n",
       " 'cut',\n",
       " 'date_range',\n",
       " 'describe_option',\n",
       " 'errors',\n",
       " 'eval',\n",
       " 'factorize',\n",
       " 'from_dummies',\n",
       " 'get_dummies',\n",
       " 'get_option',\n",
       " 'infer_freq',\n",
       " 'interval_range',\n",
       " 'io',\n",
       " 'isna',\n",
       " 'isnull',\n",
       " 'json_normalize',\n",
       " 'lreshape',\n",
       " 'melt',\n",
       " 'merge',\n",
       " 'merge_asof',\n",
       " 'merge_ordered',\n",
       " 'notna',\n",
       " 'notnull',\n",
       " 'offsets',\n",
       " 'option_context',\n",
       " 'options',\n",
       " 'pandas',\n",
       " 'period_range',\n",
       " 'pivot',\n",
       " 'pivot_table',\n",
       " 'plotting',\n",
       " 'qcut',\n",
       " 'read_clipboard',\n",
       " 'read_csv',\n",
       " 'read_excel',\n",
       " 'read_feather',\n",
       " 'read_fwf',\n",
       " 'read_gbq',\n",
       " 'read_hdf',\n",
       " 'read_html',\n",
       " 'read_json',\n",
       " 'read_orc',\n",
       " 'read_parquet',\n",
       " 'read_pickle',\n",
       " 'read_sas',\n",
       " 'read_spss',\n",
       " 'read_sql',\n",
       " 'read_sql_query',\n",
       " 'read_sql_table',\n",
       " 'read_stata',\n",
       " 'read_table',\n",
       " 'read_xml',\n",
       " 'reset_option',\n",
       " 'set_eng_float_format',\n",
       " 'set_option',\n",
       " 'show_versions',\n",
       " 'test',\n",
       " 'testing',\n",
       " 'timedelta_range',\n",
       " 'to_datetime',\n",
       " 'to_numeric',\n",
       " 'to_pickle',\n",
       " 'to_timedelta',\n",
       " 'tseries',\n",
       " 'unique',\n",
       " 'util',\n",
       " 'value_counts',\n",
       " 'wide_to_long']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir(pd)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5dcdaf5",
   "metadata": {},
   "source": [
    "# Series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a73a376",
   "metadata": {},
   "outputs": [],
   "source": [
    " # Series means 1D array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0928d738",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 2, -4, 2.2, 'data vales']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list_s = [1,2,-4,2.2,'data vales']\n",
    "list_s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "795a136c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0             1\n",
       "1             2\n",
       "2            -4\n",
       "3           2.2\n",
       "4    data vales\n",
       "dtype: object"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "series1= pd.Series(list_s)  # object means collection of different dtype\n",
    "series1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "83a41886",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.series.Series'>\n",
      "<class 'pandas.core.series.Series'>\n"
     ]
    }
   ],
   "source": [
    "print(pd.Series)  \n",
    "print(type(series1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a76c4492",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    1\n",
       "1    2\n",
       "2    3\n",
       "3    4\n",
       "dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "series2 = pd.Series([1,2,3,4])\n",
    "series2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d2f7e6d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ankush Gupta\\AppData\\Local\\Temp\\ipykernel_9996\\2492154242.py:1: FutureWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "  empty_s = pd.Series([])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Series([], dtype: float64)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "empty_s = pd.Series([])\n",
    "empty_s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "63b893fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "first     1\n",
       "second    2\n",
       "third     3\n",
       "forth     4\n",
       "dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "series3 = pd.Series([1,2,3,4], index = ['first','second','third','forth'])\n",
    "series3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4a220af7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "first     1.0\n",
       "second    2.0\n",
       "third     3.0\n",
       "forth     4.0\n",
       "dtype: float64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "series3 = pd.Series([1,2,3,4], index = ['first','second','third','forth'],dtype=float)\n",
    "series3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "932f54e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "first     1.0\n",
       "second    2.0\n",
       "third     3.0\n",
       "forth     4.0\n",
       "Name: data values, dtype: float64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "series3 = pd.Series([1,2,3,4], index = ['first','second','third','forth'],dtype=float, name = 'data values')\n",
    "series3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "20173e03",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.5\n",
       "dtype: float64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaler_s = pd.Series(0.5)  # it only for one value\n",
    "scaler_s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bf5199b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a    1\n",
      "b    2\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "dic_s = pd.Series({'a':1,'b':2})\n",
    "print(dic_s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c6d9b594",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    1\n",
       "1    2\n",
       "2    3\n",
       "3    4\n",
       "4    5\n",
       "dtype: int64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s4 = pd.Series([1,2,3,4,5])\n",
    "s4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "81cf7b36",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s4[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0e6251e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    1\n",
       "1    2\n",
       "2    3\n",
       "dtype: int64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s4[0:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e30e0447",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "print(max(s4))\n",
    "print(min(s4))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "bd605672",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3    4\n",
       "4    5\n",
       "dtype: int64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s4[s4 > 3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "715e542c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    1\n",
       "1    2\n",
       "2    3\n",
       "3    4\n",
       "4    5\n",
       "dtype: int64"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s5 = pd.Series([1,2,3,4,5,])\n",
    "s5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c551ad82",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     2\n",
       "1     4\n",
       "2     6\n",
       "3     8\n",
       "4    10\n",
       "dtype: int64"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s4 + s5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "38701b8f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    1\n",
       "1    2\n",
       "2    3\n",
       "dtype: int64"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s6 = pd.Series([1,2,3])\n",
    "s6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "09e6cac9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    2.0\n",
       "1    4.0\n",
       "2    6.0\n",
       "3    NaN\n",
       "4    NaN\n",
       "dtype: float64"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s6 + s5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "738d0369",
   "metadata": {},
   "source": [
    "# DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "702bbed6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DataFrame Means 2D and size-mutable and potentially heterogeneop tabular data structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "0189edca",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ebc2326c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: []\n",
       "Index: []"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emt_df = pd.DataFrame()\n",
    "emt_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "88637dd8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['a', 'b', 'c']"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lst = ['a','b','c']\n",
    "lst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a5d7a16a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>b</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>c</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   0\n",
       "0  a\n",
       "1  b\n",
       "2  c"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1 = pd.DataFrame(lst)\n",
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ee56f907",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>b</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>c</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   0\n",
       "0  a\n",
       "1  b\n",
       "2  c"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "400ac9d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[1, 2, 3], [2, 3, 4], [4, 5, 6]]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ls_of_ls  = [[1,2,3],[2,3,4],[4,5,6]]\n",
    "ls_of_ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "4247fb25",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   0  1  2\n",
       "0  1  2  3\n",
       "1  2  3  4\n",
       "2  4  5  6"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2 = pd.DataFrame(ls_of_ls)\n",
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "67382f2f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ID': [11, 22, 33, 44]}"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict1 = {'ID':[11,22,33,44]}\n",
    "dict1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "fad0328f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>44</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ID\n",
       "0  11\n",
       "1  22\n",
       "2  33\n",
       "3  44"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df3 = pd.DataFrame(dict1)\n",
    "df3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "4c5b525b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ID': [11, 22, 33, 44], 'SN': [1, 2, 3]}"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict1 = {'ID':[11,22,33,44],'SN':[1,2,3]}  \n",
    "dict1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "e37d397c",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "All arrays must be of the same length",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[37], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m df3 \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame(dict1)\n\u001b[0;32m      2\u001b[0m df3\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\Lib\\site-packages\\pandas\\core\\frame.py:664\u001b[0m, in \u001b[0;36mDataFrame.__init__\u001b[1;34m(self, data, index, columns, dtype, copy)\u001b[0m\n\u001b[0;32m    658\u001b[0m     mgr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_init_mgr(\n\u001b[0;32m    659\u001b[0m         data, axes\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mindex\u001b[39m\u001b[38;5;124m\"\u001b[39m: index, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcolumns\u001b[39m\u001b[38;5;124m\"\u001b[39m: columns}, dtype\u001b[38;5;241m=\u001b[39mdtype, copy\u001b[38;5;241m=\u001b[39mcopy\n\u001b[0;32m    660\u001b[0m     )\n\u001b[0;32m    662\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data, \u001b[38;5;28mdict\u001b[39m):\n\u001b[0;32m    663\u001b[0m     \u001b[38;5;66;03m# GH#38939 de facto copy defaults to False only in non-dict cases\u001b[39;00m\n\u001b[1;32m--> 664\u001b[0m     mgr \u001b[38;5;241m=\u001b[39m dict_to_mgr(data, index, columns, dtype\u001b[38;5;241m=\u001b[39mdtype, copy\u001b[38;5;241m=\u001b[39mcopy, typ\u001b[38;5;241m=\u001b[39mmanager)\n\u001b[0;32m    665\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data, ma\u001b[38;5;241m.\u001b[39mMaskedArray):\n\u001b[0;32m    666\u001b[0m     \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mma\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmrecords\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mmrecords\u001b[39;00m\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\Lib\\site-packages\\pandas\\core\\internals\\construction.py:493\u001b[0m, in \u001b[0;36mdict_to_mgr\u001b[1;34m(data, index, columns, dtype, typ, copy)\u001b[0m\n\u001b[0;32m    489\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    490\u001b[0m         \u001b[38;5;66;03m# dtype check to exclude e.g. range objects, scalars\u001b[39;00m\n\u001b[0;32m    491\u001b[0m         arrays \u001b[38;5;241m=\u001b[39m [x\u001b[38;5;241m.\u001b[39mcopy() \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(x, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdtype\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01melse\u001b[39;00m x \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m arrays]\n\u001b[1;32m--> 493\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m arrays_to_mgr(arrays, columns, index, dtype\u001b[38;5;241m=\u001b[39mdtype, typ\u001b[38;5;241m=\u001b[39mtyp, consolidate\u001b[38;5;241m=\u001b[39mcopy)\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\Lib\\site-packages\\pandas\\core\\internals\\construction.py:118\u001b[0m, in \u001b[0;36marrays_to_mgr\u001b[1;34m(arrays, columns, index, dtype, verify_integrity, typ, consolidate)\u001b[0m\n\u001b[0;32m    115\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m verify_integrity:\n\u001b[0;32m    116\u001b[0m     \u001b[38;5;66;03m# figure out the index, if necessary\u001b[39;00m\n\u001b[0;32m    117\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m index \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 118\u001b[0m         index \u001b[38;5;241m=\u001b[39m _extract_index(arrays)\n\u001b[0;32m    119\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    120\u001b[0m         index \u001b[38;5;241m=\u001b[39m ensure_index(index)\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\Lib\\site-packages\\pandas\\core\\internals\\construction.py:666\u001b[0m, in \u001b[0;36m_extract_index\u001b[1;34m(data)\u001b[0m\n\u001b[0;32m    664\u001b[0m lengths \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mset\u001b[39m(raw_lengths))\n\u001b[0;32m    665\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(lengths) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m--> 666\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAll arrays must be of the same length\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    668\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m have_dicts:\n\u001b[0;32m    669\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    670\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMixing dicts with non-Series may lead to ambiguous ordering.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    671\u001b[0m     )\n",
      "\u001b[1;31mValueError\u001b[0m: All arrays must be of the same length"
     ]
    }
   ],
   "source": [
    "df3 = pd.DataFrame(dict1)  # yaha par array   element  same hone chahiye otherwise genrate the error\n",
    "df3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "6a2b6ea2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ID': [11, 22, 33, 44], 'SN': [1, 2, 3, 5]}"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict1 = {'ID':[11,22,33,44],'SN':[1,2,3,5]}  \n",
    "dict1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "17cdefb8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>SN</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>22</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>33</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>44</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ID  SN\n",
       "0  11   1\n",
       "1  22   2\n",
       "2  33   3\n",
       "3  44   5"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df3 = pd.DataFrame(dict1)  # yaha par array element same hai to eroro nahi diya\n",
    "df3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "5c6dec5a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>a</th>\n",
       "      <th>b</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   a  b\n",
       "0  1  2\n",
       "1  3  4"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ls_dict = [{'a':1,'b':2},{'a':3,'b':4}]\n",
    "df5 = pd.DataFrame(ls_dict)\n",
    "df5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "b521514b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>a</th>\n",
       "      <th>b</th>\n",
       "      <th>c</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   a  b    c\n",
       "0  1  2  NaN\n",
       "1  3  4  5.0"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ls_dict = [{'a':1,'b':2},{'a':3,'b':4,'c':5}]\n",
    "df5 = pd.DataFrame(ls_dict)\n",
    "df5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "a24c6ec8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>SN</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>333</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Id   SN\n",
       "0   1  111\n",
       "1   2  222\n",
       "2   3  333"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict_sr ={'Id':pd.Series([1,2,3]),'SN':[111,222,333]}\n",
    "df6 = pd.DataFrame(dict_sr)\n",
    "df6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "84eebf82",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>SN</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>333</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Id   SN\n",
       "0   1  111\n",
       "1   2  222\n",
       "2   3  333"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict_sr ={'Id':pd.Series([1,2,3]),'SN':pd.Series([111,222,333])}\n",
    "df6 = pd.DataFrame(dict_sr)\n",
    "df6"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9db946e",
   "metadata": {},
   "source": [
    "# Pandas part 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "47fb9a50",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "afe650ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function read_csv in module pandas.io.parsers.readers:\n",
      "\n",
      "read_csv(filepath_or_buffer: 'FilePath | ReadCsvBuffer[bytes] | ReadCsvBuffer[str]', *, sep: 'str | None | lib.NoDefault' = <no_default>, delimiter: 'str | None | lib.NoDefault' = None, header: \"int | Sequence[int] | None | Literal['infer']\" = 'infer', names: 'Sequence[Hashable] | None | lib.NoDefault' = <no_default>, index_col: 'IndexLabel | Literal[False] | None' = None, usecols=None, squeeze: 'bool | None' = None, prefix: 'str | lib.NoDefault' = <no_default>, mangle_dupe_cols: 'bool' = True, dtype: 'DtypeArg | None' = None, engine: 'CSVEngine | None' = None, converters=None, true_values=None, false_values=None, skipinitialspace: 'bool' = False, skiprows=None, skipfooter: 'int' = 0, nrows: 'int | None' = None, na_values=None, keep_default_na: 'bool' = True, na_filter: 'bool' = True, verbose: 'bool' = False, skip_blank_lines: 'bool' = True, parse_dates=None, infer_datetime_format: 'bool' = False, keep_date_col: 'bool' = False, date_parser=None, dayfirst: 'bool' = False, cache_dates: 'bool' = True, iterator: 'bool' = False, chunksize: 'int | None' = None, compression: 'CompressionOptions' = 'infer', thousands: 'str | None' = None, decimal: 'str' = '.', lineterminator: 'str | None' = None, quotechar: 'str' = '\"', quoting: 'int' = 0, doublequote: 'bool' = True, escapechar: 'str | None' = None, comment: 'str | None' = None, encoding: 'str | None' = None, encoding_errors: 'str | None' = 'strict', dialect: 'str | csv.Dialect | None' = None, error_bad_lines: 'bool | None' = None, warn_bad_lines: 'bool | None' = None, on_bad_lines=None, delim_whitespace: 'bool' = False, low_memory=True, memory_map: 'bool' = False, float_precision: \"Literal['high', 'legacy'] | None\" = None, storage_options: 'StorageOptions' = None) -> 'DataFrame | TextFileReader'\n",
      "    Read a comma-separated values (csv) file into DataFrame.\n",
      "    \n",
      "    Also supports optionally iterating or breaking of the file\n",
      "    into chunks.\n",
      "    \n",
      "    Additional help can be found in the online docs for\n",
      "    `IO Tools <https://pandas.pydata.org/pandas-docs/stable/user_guide/io.html>`_.\n",
      "    \n",
      "    Parameters\n",
      "    ----------\n",
      "    filepath_or_buffer : str, path object or file-like object\n",
      "        Any valid string path is acceptable. The string could be a URL. Valid\n",
      "        URL schemes include http, ftp, s3, gs, and file. For file URLs, a host is\n",
      "        expected. A local file could be: file://localhost/path/to/table.csv.\n",
      "    \n",
      "        If you want to pass in a path object, pandas accepts any ``os.PathLike``.\n",
      "    \n",
      "        By file-like object, we refer to objects with a ``read()`` method, such as\n",
      "        a file handle (e.g. via builtin ``open`` function) or ``StringIO``.\n",
      "    sep : str, default ','\n",
      "        Delimiter to use. If sep is None, the C engine cannot automatically detect\n",
      "        the separator, but the Python parsing engine can, meaning the latter will\n",
      "        be used and automatically detect the separator by Python's builtin sniffer\n",
      "        tool, ``csv.Sniffer``. In addition, separators longer than 1 character and\n",
      "        different from ``'\\s+'`` will be interpreted as regular expressions and\n",
      "        will also force the use of the Python parsing engine. Note that regex\n",
      "        delimiters are prone to ignoring quoted data. Regex example: ``'\\r\\t'``.\n",
      "    delimiter : str, default ``None``\n",
      "        Alias for sep.\n",
      "    header : int, list of int, None, default 'infer'\n",
      "        Row number(s) to use as the column names, and the start of the\n",
      "        data.  Default behavior is to infer the column names: if no names\n",
      "        are passed the behavior is identical to ``header=0`` and column\n",
      "        names are inferred from the first line of the file, if column\n",
      "        names are passed explicitly then the behavior is identical to\n",
      "        ``header=None``. Explicitly pass ``header=0`` to be able to\n",
      "        replace existing names. The header can be a list of integers that\n",
      "        specify row locations for a multi-index on the columns\n",
      "        e.g. [0,1,3]. Intervening rows that are not specified will be\n",
      "        skipped (e.g. 2 in this example is skipped). Note that this\n",
      "        parameter ignores commented lines and empty lines if\n",
      "        ``skip_blank_lines=True``, so ``header=0`` denotes the first line of\n",
      "        data rather than the first line of the file.\n",
      "    names : array-like, optional\n",
      "        List of column names to use. If the file contains a header row,\n",
      "        then you should explicitly pass ``header=0`` to override the column names.\n",
      "        Duplicates in this list are not allowed.\n",
      "    index_col : int, str, sequence of int / str, or False, optional, default ``None``\n",
      "      Column(s) to use as the row labels of the ``DataFrame``, either given as\n",
      "      string name or column index. If a sequence of int / str is given, a\n",
      "      MultiIndex is used.\n",
      "    \n",
      "      Note: ``index_col=False`` can be used to force pandas to *not* use the first\n",
      "      column as the index, e.g. when you have a malformed file with delimiters at\n",
      "      the end of each line.\n",
      "    usecols : list-like or callable, optional\n",
      "        Return a subset of the columns. If list-like, all elements must either\n",
      "        be positional (i.e. integer indices into the document columns) or strings\n",
      "        that correspond to column names provided either by the user in `names` or\n",
      "        inferred from the document header row(s). If ``names`` are given, the document\n",
      "        header row(s) are not taken into account. For example, a valid list-like\n",
      "        `usecols` parameter would be ``[0, 1, 2]`` or ``['foo', 'bar', 'baz']``.\n",
      "        Element order is ignored, so ``usecols=[0, 1]`` is the same as ``[1, 0]``.\n",
      "        To instantiate a DataFrame from ``data`` with element order preserved use\n",
      "        ``pd.read_csv(data, usecols=['foo', 'bar'])[['foo', 'bar']]`` for columns\n",
      "        in ``['foo', 'bar']`` order or\n",
      "        ``pd.read_csv(data, usecols=['foo', 'bar'])[['bar', 'foo']]``\n",
      "        for ``['bar', 'foo']`` order.\n",
      "    \n",
      "        If callable, the callable function will be evaluated against the column\n",
      "        names, returning names where the callable function evaluates to True. An\n",
      "        example of a valid callable argument would be ``lambda x: x.upper() in\n",
      "        ['AAA', 'BBB', 'DDD']``. Using this parameter results in much faster\n",
      "        parsing time and lower memory usage.\n",
      "    squeeze : bool, default False\n",
      "        If the parsed data only contains one column then return a Series.\n",
      "    \n",
      "        .. deprecated:: 1.4.0\n",
      "            Append ``.squeeze(\"columns\")`` to the call to ``read_csv`` to squeeze\n",
      "            the data.\n",
      "    prefix : str, optional\n",
      "        Prefix to add to column numbers when no header, e.g. 'X' for X0, X1, ...\n",
      "    \n",
      "        .. deprecated:: 1.4.0\n",
      "           Use a list comprehension on the DataFrame's columns after calling ``read_csv``.\n",
      "    mangle_dupe_cols : bool, default True\n",
      "        Duplicate columns will be specified as 'X', 'X.1', ...'X.N', rather than\n",
      "        'X'...'X'. Passing in False will cause data to be overwritten if there\n",
      "        are duplicate names in the columns.\n",
      "    \n",
      "        .. deprecated:: 1.5.0\n",
      "            Not implemented, and a new argument to specify the pattern for the\n",
      "            names of duplicated columns will be added instead\n",
      "    dtype : Type name or dict of column -> type, optional\n",
      "        Data type for data or columns. E.g. {'a': np.float64, 'b': np.int32,\n",
      "        'c': 'Int64'}\n",
      "        Use `str` or `object` together with suitable `na_values` settings\n",
      "        to preserve and not interpret dtype.\n",
      "        If converters are specified, they will be applied INSTEAD\n",
      "        of dtype conversion.\n",
      "    \n",
      "        .. versionadded:: 1.5.0\n",
      "    \n",
      "            Support for defaultdict was added. Specify a defaultdict as input where\n",
      "            the default determines the dtype of the columns which are not explicitly\n",
      "            listed.\n",
      "    engine : {'c', 'python', 'pyarrow'}, optional\n",
      "        Parser engine to use. The C and pyarrow engines are faster, while the python engine\n",
      "        is currently more feature-complete. Multithreading is currently only supported by\n",
      "        the pyarrow engine.\n",
      "    \n",
      "        .. versionadded:: 1.4.0\n",
      "    \n",
      "            The \"pyarrow\" engine was added as an *experimental* engine, and some features\n",
      "            are unsupported, or may not work correctly, with this engine.\n",
      "    converters : dict, optional\n",
      "        Dict of functions for converting values in certain columns. Keys can either\n",
      "        be integers or column labels.\n",
      "    true_values : list, optional\n",
      "        Values to consider as True.\n",
      "    false_values : list, optional\n",
      "        Values to consider as False.\n",
      "    skipinitialspace : bool, default False\n",
      "        Skip spaces after delimiter.\n",
      "    skiprows : list-like, int or callable, optional\n",
      "        Line numbers to skip (0-indexed) or number of lines to skip (int)\n",
      "        at the start of the file.\n",
      "    \n",
      "        If callable, the callable function will be evaluated against the row\n",
      "        indices, returning True if the row should be skipped and False otherwise.\n",
      "        An example of a valid callable argument would be ``lambda x: x in [0, 2]``.\n",
      "    skipfooter : int, default 0\n",
      "        Number of lines at bottom of file to skip (Unsupported with engine='c').\n",
      "    nrows : int, optional\n",
      "        Number of rows of file to read. Useful for reading pieces of large files.\n",
      "    na_values : scalar, str, list-like, or dict, optional\n",
      "        Additional strings to recognize as NA/NaN. If dict passed, specific\n",
      "        per-column NA values.  By default the following values are interpreted as\n",
      "        NaN: '', '#N/A', '#N/A N/A', '#NA', '-1.#IND', '-1.#QNAN', '-NaN', '-nan',\n",
      "        '1.#IND', '1.#QNAN', '<NA>', 'N/A', 'NA', 'NULL', 'NaN', 'n/a',\n",
      "        'nan', 'null'.\n",
      "    keep_default_na : bool, default True\n",
      "        Whether or not to include the default NaN values when parsing the data.\n",
      "        Depending on whether `na_values` is passed in, the behavior is as follows:\n",
      "    \n",
      "        * If `keep_default_na` is True, and `na_values` are specified, `na_values`\n",
      "          is appended to the default NaN values used for parsing.\n",
      "        * If `keep_default_na` is True, and `na_values` are not specified, only\n",
      "          the default NaN values are used for parsing.\n",
      "        * If `keep_default_na` is False, and `na_values` are specified, only\n",
      "          the NaN values specified `na_values` are used for parsing.\n",
      "        * If `keep_default_na` is False, and `na_values` are not specified, no\n",
      "          strings will be parsed as NaN.\n",
      "    \n",
      "        Note that if `na_filter` is passed in as False, the `keep_default_na` and\n",
      "        `na_values` parameters will be ignored.\n",
      "    na_filter : bool, default True\n",
      "        Detect missing value markers (empty strings and the value of na_values). In\n",
      "        data without any NAs, passing na_filter=False can improve the performance\n",
      "        of reading a large file.\n",
      "    verbose : bool, default False\n",
      "        Indicate number of NA values placed in non-numeric columns.\n",
      "    skip_blank_lines : bool, default True\n",
      "        If True, skip over blank lines rather than interpreting as NaN values.\n",
      "    parse_dates : bool or list of int or names or list of lists or dict, default False\n",
      "        The behavior is as follows:\n",
      "    \n",
      "        * boolean. If True -> try parsing the index.\n",
      "        * list of int or names. e.g. If [1, 2, 3] -> try parsing columns 1, 2, 3\n",
      "          each as a separate date column.\n",
      "        * list of lists. e.g.  If [[1, 3]] -> combine columns 1 and 3 and parse as\n",
      "          a single date column.\n",
      "        * dict, e.g. {'foo' : [1, 3]} -> parse columns 1, 3 as date and call\n",
      "          result 'foo'\n",
      "    \n",
      "        If a column or index cannot be represented as an array of datetimes,\n",
      "        say because of an unparsable value or a mixture of timezones, the column\n",
      "        or index will be returned unaltered as an object data type. For\n",
      "        non-standard datetime parsing, use ``pd.to_datetime`` after\n",
      "        ``pd.read_csv``. To parse an index or column with a mixture of timezones,\n",
      "        specify ``date_parser`` to be a partially-applied\n",
      "        :func:`pandas.to_datetime` with ``utc=True``. See\n",
      "        :ref:`io.csv.mixed_timezones` for more.\n",
      "    \n",
      "        Note: A fast-path exists for iso8601-formatted dates.\n",
      "    infer_datetime_format : bool, default False\n",
      "        If True and `parse_dates` is enabled, pandas will attempt to infer the\n",
      "        format of the datetime strings in the columns, and if it can be inferred,\n",
      "        switch to a faster method of parsing them. In some cases this can increase\n",
      "        the parsing speed by 5-10x.\n",
      "    keep_date_col : bool, default False\n",
      "        If True and `parse_dates` specifies combining multiple columns then\n",
      "        keep the original columns.\n",
      "    date_parser : function, optional\n",
      "        Function to use for converting a sequence of string columns to an array of\n",
      "        datetime instances. The default uses ``dateutil.parser.parser`` to do the\n",
      "        conversion. Pandas will try to call `date_parser` in three different ways,\n",
      "        advancing to the next if an exception occurs: 1) Pass one or more arrays\n",
      "        (as defined by `parse_dates`) as arguments; 2) concatenate (row-wise) the\n",
      "        string values from the columns defined by `parse_dates` into a single array\n",
      "        and pass that; and 3) call `date_parser` once for each row using one or\n",
      "        more strings (corresponding to the columns defined by `parse_dates`) as\n",
      "        arguments.\n",
      "    dayfirst : bool, default False\n",
      "        DD/MM format dates, international and European format.\n",
      "    cache_dates : bool, default True\n",
      "        If True, use a cache of unique, converted dates to apply the datetime\n",
      "        conversion. May produce significant speed-up when parsing duplicate\n",
      "        date strings, especially ones with timezone offsets.\n",
      "    \n",
      "        .. versionadded:: 0.25.0\n",
      "    iterator : bool, default False\n",
      "        Return TextFileReader object for iteration or getting chunks with\n",
      "        ``get_chunk()``.\n",
      "    \n",
      "        .. versionchanged:: 1.2\n",
      "    \n",
      "           ``TextFileReader`` is a context manager.\n",
      "    chunksize : int, optional\n",
      "        Return TextFileReader object for iteration.\n",
      "        See the `IO Tools docs\n",
      "        <https://pandas.pydata.org/pandas-docs/stable/io.html#io-chunking>`_\n",
      "        for more information on ``iterator`` and ``chunksize``.\n",
      "    \n",
      "        .. versionchanged:: 1.2\n",
      "    \n",
      "           ``TextFileReader`` is a context manager.\n",
      "    compression : str or dict, default 'infer'\n",
      "        For on-the-fly decompression of on-disk data. If 'infer' and 'filepath_or_buffer' is\n",
      "        path-like, then detect compression from the following extensions: '.gz',\n",
      "        '.bz2', '.zip', '.xz', '.zst', '.tar', '.tar.gz', '.tar.xz' or '.tar.bz2'\n",
      "        (otherwise no compression).\n",
      "        If using 'zip' or 'tar', the ZIP file must contain only one data file to be read in.\n",
      "        Set to ``None`` for no decompression.\n",
      "        Can also be a dict with key ``'method'`` set\n",
      "        to one of {``'zip'``, ``'gzip'``, ``'bz2'``, ``'zstd'``, ``'tar'``} and other\n",
      "        key-value pairs are forwarded to\n",
      "        ``zipfile.ZipFile``, ``gzip.GzipFile``,\n",
      "        ``bz2.BZ2File``, ``zstandard.ZstdDecompressor`` or\n",
      "        ``tarfile.TarFile``, respectively.\n",
      "        As an example, the following could be passed for Zstandard decompression using a\n",
      "        custom compression dictionary:\n",
      "        ``compression={'method': 'zstd', 'dict_data': my_compression_dict}``.\n",
      "    \n",
      "            .. versionadded:: 1.5.0\n",
      "                Added support for `.tar` files.\n",
      "    \n",
      "        .. versionchanged:: 1.4.0 Zstandard support.\n",
      "    \n",
      "    thousands : str, optional\n",
      "        Thousands separator.\n",
      "    decimal : str, default '.'\n",
      "        Character to recognize as decimal point (e.g. use ',' for European data).\n",
      "    lineterminator : str (length 1), optional\n",
      "        Character to break file into lines. Only valid with C parser.\n",
      "    quotechar : str (length 1), optional\n",
      "        The character used to denote the start and end of a quoted item. Quoted\n",
      "        items can include the delimiter and it will be ignored.\n",
      "    quoting : int or csv.QUOTE_* instance, default 0\n",
      "        Control field quoting behavior per ``csv.QUOTE_*`` constants. Use one of\n",
      "        QUOTE_MINIMAL (0), QUOTE_ALL (1), QUOTE_NONNUMERIC (2) or QUOTE_NONE (3).\n",
      "    doublequote : bool, default ``True``\n",
      "       When quotechar is specified and quoting is not ``QUOTE_NONE``, indicate\n",
      "       whether or not to interpret two consecutive quotechar elements INSIDE a\n",
      "       field as a single ``quotechar`` element.\n",
      "    escapechar : str (length 1), optional\n",
      "        One-character string used to escape other characters.\n",
      "    comment : str, optional\n",
      "        Indicates remainder of line should not be parsed. If found at the beginning\n",
      "        of a line, the line will be ignored altogether. This parameter must be a\n",
      "        single character. Like empty lines (as long as ``skip_blank_lines=True``),\n",
      "        fully commented lines are ignored by the parameter `header` but not by\n",
      "        `skiprows`. For example, if ``comment='#'``, parsing\n",
      "        ``#empty\\na,b,c\\n1,2,3`` with ``header=0`` will result in 'a,b,c' being\n",
      "        treated as the header.\n",
      "    encoding : str, optional\n",
      "        Encoding to use for UTF when reading/writing (ex. 'utf-8'). `List of Python\n",
      "        standard encodings\n",
      "        <https://docs.python.org/3/library/codecs.html#standard-encodings>`_ .\n",
      "    \n",
      "        .. versionchanged:: 1.2\n",
      "    \n",
      "           When ``encoding`` is ``None``, ``errors=\"replace\"`` is passed to\n",
      "           ``open()``. Otherwise, ``errors=\"strict\"`` is passed to ``open()``.\n",
      "           This behavior was previously only the case for ``engine=\"python\"``.\n",
      "    \n",
      "        .. versionchanged:: 1.3.0\n",
      "    \n",
      "           ``encoding_errors`` is a new argument. ``encoding`` has no longer an\n",
      "           influence on how encoding errors are handled.\n",
      "    \n",
      "    encoding_errors : str, optional, default \"strict\"\n",
      "        How encoding errors are treated. `List of possible values\n",
      "        <https://docs.python.org/3/library/codecs.html#error-handlers>`_ .\n",
      "    \n",
      "        .. versionadded:: 1.3.0\n",
      "    \n",
      "    dialect : str or csv.Dialect, optional\n",
      "        If provided, this parameter will override values (default or not) for the\n",
      "        following parameters: `delimiter`, `doublequote`, `escapechar`,\n",
      "        `skipinitialspace`, `quotechar`, and `quoting`. If it is necessary to\n",
      "        override values, a ParserWarning will be issued. See csv.Dialect\n",
      "        documentation for more details.\n",
      "    error_bad_lines : bool, optional, default ``None``\n",
      "        Lines with too many fields (e.g. a csv line with too many commas) will by\n",
      "        default cause an exception to be raised, and no DataFrame will be returned.\n",
      "        If False, then these \"bad lines\" will be dropped from the DataFrame that is\n",
      "        returned.\n",
      "    \n",
      "        .. deprecated:: 1.3.0\n",
      "           The ``on_bad_lines`` parameter should be used instead to specify behavior upon\n",
      "           encountering a bad line instead.\n",
      "    warn_bad_lines : bool, optional, default ``None``\n",
      "        If error_bad_lines is False, and warn_bad_lines is True, a warning for each\n",
      "        \"bad line\" will be output.\n",
      "    \n",
      "        .. deprecated:: 1.3.0\n",
      "           The ``on_bad_lines`` parameter should be used instead to specify behavior upon\n",
      "           encountering a bad line instead.\n",
      "    on_bad_lines : {'error', 'warn', 'skip'} or callable, default 'error'\n",
      "        Specifies what to do upon encountering a bad line (a line with too many fields).\n",
      "        Allowed values are :\n",
      "    \n",
      "            - 'error', raise an Exception when a bad line is encountered.\n",
      "            - 'warn', raise a warning when a bad line is encountered and skip that line.\n",
      "            - 'skip', skip bad lines without raising or warning when they are encountered.\n",
      "    \n",
      "        .. versionadded:: 1.3.0\n",
      "    \n",
      "        .. versionadded:: 1.4.0\n",
      "    \n",
      "            - callable, function with signature\n",
      "              ``(bad_line: list[str]) -> list[str] | None`` that will process a single\n",
      "              bad line. ``bad_line`` is a list of strings split by the ``sep``.\n",
      "              If the function returns ``None``, the bad line will be ignored.\n",
      "              If the function returns a new list of strings with more elements than\n",
      "              expected, a ``ParserWarning`` will be emitted while dropping extra elements.\n",
      "              Only supported when ``engine=\"python\"``\n",
      "    \n",
      "    delim_whitespace : bool, default False\n",
      "        Specifies whether or not whitespace (e.g. ``' '`` or ``'    '``) will be\n",
      "        used as the sep. Equivalent to setting ``sep='\\s+'``. If this option\n",
      "        is set to True, nothing should be passed in for the ``delimiter``\n",
      "        parameter.\n",
      "    low_memory : bool, default True\n",
      "        Internally process the file in chunks, resulting in lower memory use\n",
      "        while parsing, but possibly mixed type inference.  To ensure no mixed\n",
      "        types either set False, or specify the type with the `dtype` parameter.\n",
      "        Note that the entire file is read into a single DataFrame regardless,\n",
      "        use the `chunksize` or `iterator` parameter to return the data in chunks.\n",
      "        (Only valid with C parser).\n",
      "    memory_map : bool, default False\n",
      "        If a filepath is provided for `filepath_or_buffer`, map the file object\n",
      "        directly onto memory and access the data directly from there. Using this\n",
      "        option can improve performance because there is no longer any I/O overhead.\n",
      "    float_precision : str, optional\n",
      "        Specifies which converter the C engine should use for floating-point\n",
      "        values. The options are ``None`` or 'high' for the ordinary converter,\n",
      "        'legacy' for the original lower precision pandas converter, and\n",
      "        'round_trip' for the round-trip converter.\n",
      "    \n",
      "        .. versionchanged:: 1.2\n",
      "    \n",
      "    storage_options : dict, optional\n",
      "        Extra options that make sense for a particular storage connection, e.g.\n",
      "        host, port, username, password, etc. For HTTP(S) URLs the key-value pairs\n",
      "        are forwarded to ``urllib.request.Request`` as header options. For other\n",
      "        URLs (e.g. starting with \"s3://\", and \"gcs://\") the key-value pairs are\n",
      "        forwarded to ``fsspec.open``. Please see ``fsspec`` and ``urllib`` for more\n",
      "        details, and for more examples on storage options refer `here\n",
      "        <https://pandas.pydata.org/docs/user_guide/io.html?\n",
      "        highlight=storage_options#reading-writing-remote-files>`_.\n",
      "    \n",
      "        .. versionadded:: 1.2\n",
      "    \n",
      "    Returns\n",
      "    -------\n",
      "    DataFrame or TextParser\n",
      "        A comma-separated values (csv) file is returned as two-dimensional\n",
      "        data structure with labeled axes.\n",
      "    \n",
      "    See Also\n",
      "    --------\n",
      "    DataFrame.to_csv : Write DataFrame to a comma-separated values (csv) file.\n",
      "    read_csv : Read a comma-separated values (csv) file into DataFrame.\n",
      "    read_fwf : Read a table of fixed-width formatted lines into DataFrame.\n",
      "    \n",
      "    Examples\n",
      "    --------\n",
      "    >>> pd.read_csv('data.csv')  # doctest: +SKIP\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(pd.read_csv)  # it give detail about read_csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1a2403d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>day</th>\n",
       "      <th>temperature</th>\n",
       "      <th>windspeed</th>\n",
       "      <th>event</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1/1/2017</td>\n",
       "      <td>32.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>Rain</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1/4/2017</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9.0</td>\n",
       "      <td>Sunny</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1/5/2017</td>\n",
       "      <td>28.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Snow</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1/6/2017</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1/7/2017</td>\n",
       "      <td>32.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Rain</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1/8/2017</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Sunny</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1/9/2017</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1/10/2017</td>\n",
       "      <td>34.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>Cloudy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1/11/2017</td>\n",
       "      <td>40.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>Sunny</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         day  temperature  windspeed   event\n",
       "0   1/1/2017         32.0        6.0    Rain\n",
       "1   1/4/2017          NaN        9.0   Sunny\n",
       "2   1/5/2017         28.0        NaN    Snow\n",
       "3   1/6/2017          NaN        7.0     NaN\n",
       "4   1/7/2017         32.0        NaN    Rain\n",
       "5   1/8/2017          NaN        NaN   Sunny\n",
       "6   1/9/2017          NaN        NaN     NaN\n",
       "7  1/10/2017         34.0        8.0  Cloudy\n",
       "8  1/11/2017         40.0       12.0   Sunny"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_csv('weather_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f911b3e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "deda4505",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ankush Gupta\\Machine Learning\\ML Full Course By India AI Production\\Pandas By India AI Production\n"
     ]
    }
   ],
   "source": [
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27360a0d",
   "metadata": {},
   "source": [
    "# Day 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd7a0320",
   "metadata": {},
   "outputs": [],
   "source": [
    "how to "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
